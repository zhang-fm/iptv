import os
import re
import time
import requests
import concurrent.futures
import sys
import random
import functools

# å¼ºåˆ¶å®æ—¶åˆ·æ–°è¾“å‡º
print = functools.partial(print, flush=True)

# ===============================
# é…ç½®åŒº
# ===============================
INPUT_FILES = ["py/live.txt", "py/IPTV2.txt"]
OUTPUT_FILE = "py/livezubo.txt"
BLACKLIST_FILE = "py/blacklist.txt"

CHECK_COUNT = 3      # æ¯ä¸ªæœåŠ¡å™¨æŠ½æµ‹ 3 ä¸ªé¢‘é“
CHECK_TIMEOUT = 10   # æ¯ä¸ªé¢‘é“è¶…æ—¶æ—¶é—´
MIN_PEAK_REQUIRED = 0.50  # å³°å€¼é—¨æ§› MB/s

def load_blacklist():
    if os.path.exists(BLACKLIST_FILE):
        with open(BLACKLIST_FILE, "r", encoding="utf-8") as f:
            return set(line.strip() for line in f if line.strip())
    return set()

def save_to_blacklist(ip):
    with open(BLACKLIST_FILE, "a", encoding="utf-8") as f:
        f.write(ip + "\n")

def get_realtime_speed(url):
    try:
        start_time = time.time()
        res = requests.get(url, timeout=CHECK_TIMEOUT, stream=True, headers={'User-Agent': 'vlc/3.0.8'})
        if res.status_code != 200: return 0
        
        chunk = res.raw.read(1024 * 1024) # è¯» 1MB
        duration = time.time() - start_time
        return 1.0 / duration if duration > 0 else 0
    except:
        return 0

def test_ip_group(ip_port, channels):
    """æµ‹è¯•æŸä¸ªIPä¸‹çš„éšæœºé¢‘é“"""
    all_urls = [url for _, url in channels]
    test_targets = random.sample(all_urls, min(len(all_urls), CHECK_COUNT))
    best_peak = 0.0
    alive_count = 0

    for url in test_targets:
        speed = get_realtime_speed(url)
        if speed > 0.01:
            alive_count += 1
            if speed > best_peak: best_peak = speed

    return ip_port, best_peak, (alive_count > 0)

def main():
    print(f"ğŸ“… ä»»åŠ¡å¯åŠ¨æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    if not os.path.exists(BLACKLIST_FILE):
        open(BLACKLIST_FILE, 'w').close()
        print("ğŸ†• å·²åˆ›å»ºæ–°çš„é»‘åå•æ–‡ä»¶")

    blacklist = load_blacklist()
    
    # æ ¸å¿ƒæ•°æ®ç»“æ„
    # { "åˆ†ç±»åç§°": { "ip:port": [(name, url), ...] } }
    category_map = {}
    
    # 1. è§£æè¾“å…¥æ–‡ä»¶å¹¶ä¿ç•™åˆ†ç±»
    for f_path in INPUT_FILES:
        if not os.path.exists(f_path): continue
        
        current_category = "æœªåˆ†ç±»"
        with open(f_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line: continue
                
                # è¯†åˆ«åˆ†ç±»è¡Œ (ä¾‹å¦‚: å¤®è§†é¢‘é“,#genre#)
                if "#genre#" in line:
                    current_category = line.split(",")[0].strip()
                    continue
                
                # è¯†åˆ«é¢‘é“è¡Œ (ä¾‹å¦‚: CCTV1,http://ip:port/...)
                if "," in line and "http" in line:
                    parts = line.split(",", 1)
                    ch_name = parts[0].strip()
                    url = parts[1].strip()
                    
                    # æå– IP:Port
                    match = re.search(r'http://(.*?)/', url)
                    if match:
                        ip_port = match.group(1)
                        if ip_port in blacklist: continue
                        
                        # æ„å»ºåµŒå¥—å­—å…¸
                        if current_category not in category_map:
                            category_map[current_category] = {}
                        if ip_port not in category_map[current_category]:
                            category_map[current_category][ip_port] = []
                        
                        category_map[current_category][ip_port].append((ch_name, url))

    # 2. æå–æ‰€æœ‰å”¯ä¸€çš„ IP:Port è¿›è¡Œæµ‹é€Ÿï¼ˆé¿å…é‡å¤æµ‹é€Ÿï¼‰
    unique_ips = {}
    for cat_dict in category_map.values():
        for ip, channels in cat_dict.items():
            if ip not in unique_ips:
                unique_ips[ip] = channels

    total_ips = len(unique_ips)
    print(f"ğŸš€ å‘ç° {len(category_map)} ä¸ªåˆ†ç±»ï¼Œå‡†å¤‡æµ‹è¯• {total_ips} ä¸ªæœåŠ¡å™¨")
    print("-" * 50)

    # 3. å¹¶è¡Œæµ‹é€Ÿ
    valid_ips = {} # å­˜å‚¨è¾¾æ ‡çš„ IP åŠå…¶å³°å€¼
    new_dead_ips = []
    done_count = 0

    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = {executor.submit(test_ip_group, ip, chs): ip for ip, chs in unique_ips.items()}
        for future in concurrent.futures.as_completed(futures):
            done_count += 1
            ip, peak, is_alive = future.result()
            
            status_icon = "âœ…" if is_alive else "âŒ"
            print(f"[{done_count}/{total_ips}] {status_icon} {ip:20} | å³°å€¼: {peak:5.2f} MB/s")
            
            if not is_alive:
                new_dead_ips.append(ip)
                save_to_blacklist(ip)
            elif peak >= MIN_PEAK_REQUIRED:
                valid_ips[ip] = peak

    # 4. æŒ‰åˆ†ç±»å†™å…¥ç»“æœæ–‡ä»¶
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for cat_name, ip_dict in category_map.items():
            # æ£€æŸ¥è¯¥åˆ†ç±»ä¸‹æ˜¯å¦æœ‰è¾¾æ ‡çš„ IP
            cat_content = []
            for ip in ip_dict:
                if ip in valid_ips:
                    for ch_name, url in ip_dict[ip]:
                        cat_content.append(f"{ch_name},{url}")
            
            # å¦‚æœè¯¥åˆ†ç±»ä¸‹æœ‰æ´»çš„é¢‘é“ï¼Œåˆ™å†™å…¥åˆ†ç±»æ ‡é¢˜å’Œå†…å®¹
            if cat_content:
                f.write(f"{cat_name},#genre#\n")
                for item in cat_content:
                    f.write(f"{item}\n")
                f.write("\n") # åˆ†ç±»é—´ç•™ç©ºè¡Œ

    print("-" * 50)
    print(f"âœ¨ æµ‹é€Ÿæ€»ç»“:")
    print(f"   - è¾¾æ ‡ä¿ç•™æœåŠ¡å™¨: {len(valid_ips)}")
    print(f"   - æœ¬æ¬¡æ–°å¢é»‘åå•: {len(new_dead_ips)}")
    print(f"   - ç»“æœå·²ä¿å­˜è‡³: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
